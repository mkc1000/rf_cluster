No handlers could be found for logger "root"
downloading Cal. housing from http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.tgz to /home/ubuntu/scikit_learn_data
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:89: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  self.slms = Parallel(n_jobs=self.n_jobs)(delayed(fit_sl_model)(self, X, i, features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/rf_cluster/slcluster.py:118: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  decision_paths = Parallel(n_jobs=self.n_jobs)(delayed(get_predictions)(self,X,i,features_to_predict) for i, features_to_predict in enumerate(self.features_indices))
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1
  **self._backend_args)
Traceback (most recent call last):
  File "test_new.py", line 77, in <module>
    fit_model_output = Parallel(n_jobs=-1)(delayed(fit_model)(model) for model in models_to_search)
  File "/home/ubuntu/anaconda2/lib/python2.7/site-packages/joblib/parallel.py", line 810, in __call__
    self.retrieve()
  File "/home/ubuntu/anaconda2/lib/python2.7/site-packages/joblib/parallel.py", line 757, in retrieve
    raise exception
joblib.my_exceptions.JoblibMemoryError: JoblibMemoryError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/ubuntu/rf_cluster/test_new.py in <module>()
     72         params.append(param)
     73     return params
     74 
     75 if __name__ == '__main__':
     76     models_to_search = grid_search(SLC_PARAMS)
---> 77     fit_model_output = Parallel(n_jobs=-1)(delayed(fit_model)(model) for model in models_to_search)
     78     with open('big_ole_grid_search_new_datasets.pkl','w') as f:
     79         pickle.dump(fit_model_output, f)
     80     params_per_dataset = select_params_per_dataset_per_k(fit_model_output)
     81     params_to_retry = prepare_tuned_models(params_per_dataset)

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    805             if pre_dispatch == "all" or n_jobs == 1:
    806                 # The iterable was consumed all at once by the above for loop.
    807                 # No need to wait for async callbacks to trigger to
    808                 # consumption.
    809                 self._iterating = False
--> 810             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    811             # Make sure that we get a last message telling us we are done
    812             elapsed_time = time.time() - self._start_time
    813             self._print('Done %3i out of %3i | elapsed: %s finished',
    814                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
MemoryError                                        Tue Nov 22 00:49:56 2016
PID: 1758                  Python 2.7.12: /home/ubuntu/anaconda2/bin/python
...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)
     67     def __init__(self, iterator_slice):
     68         self.items = list(iterator_slice)
     69         self._size = len(self.items)
     70 
     71     def __call__(self):
---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function fit_model>
        args = ({'k': 2, 'kmeans_type': 'squishy', 'max_depth': 3, 'n_features_to_predict': 0.5, 'n_forests': 100, 'n_jobs': -1, 'n_trees': 1, 'using_pca': True, 'weight_extent': 0},)
        kwargs = {}
        self.items = [(<function fit_model>, ({'k': 2, 'kmeans_type': 'squishy', 'max_depth': 3, 'n_features_to_predict': 0.5, 'n_forests': 100, 'n_jobs': -1, 'n_trees': 1, 'using_pca': True, 'weight_extent': 0},), {})]
     73 
     74     def __len__(self):
     75         return self._size
     76 

...........................................................................
/home/ubuntu/rf_cluster/test_new.py in fit_model(params={'k': 2, 'kmeans_type': 'squishy', 'max_depth': 3, 'n_features_to_predict': 0.5, 'n_forests': 100, 'n_jobs': -1, 'n_trees': 1, 'using_pca': True, 'weight_extent': 0})
     43     dataset = params.pop('dataset')
     44     data = DATASETS[dataset]
     45     Model = params.pop('model')
     46     slc_model = Model(**params)
     47     wcv = WCVScore(slc_model)
---> 48     wcv_score, n_clusters = wcv.score(data)
        wcv_score = undefined
        n_clusters = undefined
        wcv.score = <bound method WCVScore.score of <within_cluster_variance.WCVScore object>>
        data = array([[  2.59600000e+03,   5.10000000e+01,   3....000000e+00,   0.00000000e+00,   0.00000000e+00]])
     49     return dataset, params, wcv_score, n_clusters
     50 
     51 def select_params_per_dataset_per_k(fit_model_output):
     52     datasets = [tup[0] for tup in fit_model_output]

...........................................................................
/home/ubuntu/rf_cluster/within_cluster_variance.py in score(self=<within_cluster_variance.WCVScore object>, data=array([[  2.59600000e+03,   5.10000000e+01,   3....000000e+00,   0.00000000e+00,   0.00000000e+00]]))
     41         self.wcvs = []
     42         n_features = data.shape[1]
     43         features = np.arange(n_features)
     44         if n_features > self.max_iter:
     45             features = np.random.choice(features,size=self.max_iter,replace=False)
---> 46         output = Parallel(n_jobs=self.n_jobs)(delayed(score_once)(self, data, i) for i in features)
        output = undefined
        self.n_jobs = 1
        self = <within_cluster_variance.WCVScore object>
        data = array([[  2.59600000e+03,   5.10000000e+01,   3....000000e+00,   0.00000000e+00,   0.00000000e+00]])
        features = array([43, 30,  7, 24, 35, 46, 49, 45, 27, 11])
     47         output = np.array(output)
     48         self.wcvs = output[:,0]
     49         self.n_clusters = output[:,1]
     50         return np.mean(self.wcvs), np.mean(self.n_clusters)

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    795         self._smoothed_batch_duration = 0.0
    796         try:
    797             # Only set self._iterating to True if at least a batch
    798             # was dispatched. In particular this covers the edge
    799             # case of Parallel used with an exhausted iterator.
--> 800             while self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    801                 self._iterating = True
    802             else:
    803                 self._iterating = False
    804 

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    653             tasks = BatchedCalls(itertools.islice(iterator, batch_size))
    654             if not tasks:
    655                 # No more tasks available in the iterator: tell caller to stop.
    656                 return False
    657             else:
--> 658                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <joblib.parallel.BatchedCalls object>
    659                 return True
    660 
    661     def _print(self, msg, msg_args):
    662         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<joblib.parallel.BatchedCalls object>)
    561         # If job.get() catches an exception, it closes the queue:
    562         if self._aborting:
    563             return
    564 
    565         if self._pool is None:
--> 566             job = ImmediateComputeBatch(batch)
        job = undefined
        batch = <joblib.parallel.BatchedCalls object>
    567             self._jobs.append(job)
    568             self.n_dispatched_batches += 1
    569             self.n_dispatched_tasks += len(batch)
    570             self.n_completed_tasks += len(batch)

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/joblib/parallel.py in __init__(self=<joblib.parallel.ImmediateComputeBatch object>, batch=<joblib.parallel.BatchedCalls object>)
    175 
    176     """
    177     def __init__(self, batch):
    178         # Don't delay the application, to avoid keeping the input
    179         # arguments in memory
--> 180         self.results = batch()
        self.results = undefined
        batch = <joblib.parallel.BatchedCalls object>
    181 
    182     def get(self):
    183         return self.results
    184 

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)
     67     def __init__(self, iterator_slice):
     68         self.items = list(iterator_slice)
     69         self._size = len(self.items)
     70 
     71     def __call__(self):
---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function score_once>
        args = (<within_cluster_variance.WCVScore object>, array([[  2.59600000e+03,   5.10000000e+01,   3....000000e+00,   0.00000000e+00,   0.00000000e+00]]), 43)
        kwargs = {}
        self.items = [(<function score_once>, (<within_cluster_variance.WCVScore object>, array([[  2.59600000e+03,   5.10000000e+01,   3....000000e+00,   0.00000000e+00,   0.00000000e+00]]), 43), {})]
     73 
     74     def __len__(self):
     75         return self._size
     76 

...........................................................................
/home/ubuntu/rf_cluster/within_cluster_variance.py in score_once(wcv=<within_cluster_variance.WCVScore object>, data=array([[  2.59600000e+03,   5.10000000e+01,   3....000000e+00,   0.00000000e+00,   0.00000000e+00]]), i=43)
     20 """
     21 
     22 def score_once(wcv, data, i):
     23     y = data[:,i]
     24     X = np.delete(data, i, axis=1)
---> 25     predictions = wcv.model.fit_predict(X)
        predictions = undefined
        wcv.model.fit_predict = <function fit_predict>
        X = array([[  2.59600000e+03,   5.10000000e+01,   3....000000e+00,   0.00000000e+00,   0.00000000e+00]])
     26     n_clusters = len(np.unique(predictions))
     27     within_cluster_variance = mean_cluster_variances(predictions, y)
     28     total_variance = np.var(y)
     29     scaled_within_cluster_variance = within_cluster_variance / total_variance

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(array([[  2.59600000e+03,   5.10000000e+01,   3....000000e+00,   0.00000000e+00,   0.00000000e+00]]),), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (array([[  2.59600000e+03,   5.10000000e+01,   3....000000e+00,   0.00000000e+00,   0.00000000e+00]]),)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.py in fit_predict(self=FullSLCluster(eig_extent=None, k=None, kmeans_ty...      weight_adjustment=None, weight_extent=None), X=array([[  2.59600000e+03,   5.10000000e+01,   3....000000e+00,   0.00000000e+00,   0.00000000e+00]]), y=None, **fit_params={})
    352         Returns
    353         -------
    354         y_pred : array-like
    355         """
    356         Xt, fit_params = self._fit(X, y, **fit_params)
--> 357         return self.steps[-1][-1].fit_predict(Xt, y, **fit_params)
        self.steps.fit_predict = undefined
        Xt = array([[-0.23295163, -0.91122639, -0.07058159, ....  0.62713595,
         4.94124995, -1.99368361]])
        y = None
        fit_params = {}
    358 
    359     @if_delegate_has_method(delegate='_final_estimator')
    360     def predict_proba(self, X):
    361         """Apply transforms, and predict_proba of the final estimator

...........................................................................
/home/ubuntu/rf_cluster/slcluster.py in fit_predict(self=<slcluster.SquishyJKMeans object>, X=array([[-0.23295163, -0.91122639, -0.07058159, ....  0.62713595,
         4.94124995, -1.99368361]]), _=None)
    358                     self.assignment_score = score
    359                     self.assignments = assignments
    360         return self
    361 
    362     def fit_predict(self, X, _=None):
--> 363         self.fit(X)
        self.fit = <bound method SquishyJKMeans.fit of <slcluster.SquishyJKMeans object>>
        X = array([[-0.23295163, -0.91122639, -0.07058159, ....  0.62713595,
         4.94124995, -1.99368361]])
    364         return self.assignments
    365 
    366 
    367 

...........................................................................
/home/ubuntu/rf_cluster/slcluster.py in fit(self=<slcluster.SquishyJKMeans object>, X=array([[-0.23295163, -0.91122639, -0.07058159, ....  0.62713595,
         4.94124995, -1.99368361]]))
    344     def fit(self, X):
    345         if self.accepting_weights:
    346             X, self.weights = X
    347         else:
    348             self.weights = np.ones(X.shape[1])/X.shape[1]
--> 349         self.distance_matrix = weighted_jaccard_distance_matrix(X, self.weights, n_jobs=self.n_jobs)
        self.distance_matrix = None
        X = array([[-0.23295163, -0.91122639, -0.07058159, ....  0.62713595,
         4.94124995, -1.99368361]])
        self.weights = array([ 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,... 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])
        self.n_jobs = -1
    350         for _ in xrange(self.n_attempts):
    351             assignments = self.fit_once(X)
    352             if self.assignments is None:
    353                 self.assignments = assignments

...........................................................................
/home/ubuntu/rf_cluster/slcluster.py in weighted_jaccard_distance_matrix(X=array([[-0.23295163, -0.91122639, -0.07058159, ....  0.62713595,
         4.94124995, -1.99368361]]), w=array([ 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,... 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01]), n_jobs=-1)
    194 def weighted_jaccard_distance_matrix(X, w, n_jobs=1):
    195     """w has length X.shape[1]"""
    196     vint = np.vectorize(int)
    197     X_int = vint(X*100)
    198     print "starting to make distance matrix"
--> 199     distance_matrix = pairwise_distances(X_int, w=w, metric=weighted_jaccard,n_jobs=n_jobs)
        distance_matrix = undefined
        X_int = array([[ -23,  -91,   -7, ..., -196,  -75,  -92]...      [ -23,  277,   -7, ...,   62,  494, -199]])
        w = array([ 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,... 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])
        n_jobs = -1
    200     print "done making distance matrix"
    201     return distance_matrix
    202 
    203 class JKMeans(object):

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X=array([[ -23,  -91,   -7, ..., -196,  -75,  -92]...      [ -23,  277,   -7, ...,   62,  494, -199]]), Y=None, metric=<function weighted_jaccard>, n_jobs=-1, **kwds={'w': array([ 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,... 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])})
   1235         if n_jobs == 1 and X is Y:
   1236             return distance.squareform(distance.pdist(X, metric=metric,
   1237                                                       **kwds))
   1238         func = partial(distance.cdist, metric=metric, **kwds)
   1239 
-> 1240     return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
        X = array([[ -23,  -91,   -7, ..., -196,  -75,  -92]...      [ -23,  277,   -7, ...,   62,  494, -199]])
        Y = None
        func = <functools.partial object>
        n_jobs = -1
        kwds = {'w': array([ 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,... 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])}
   1241 
   1242 
   1243 # These distances recquire boolean arrays, when using scipy.spatial.distance
   1244 PAIRWISE_BOOLEAN_FUNCTIONS = [

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/pairwise.py in _parallel_pairwise(X=array([[ -23,  -91,   -7, ..., -196,  -75,  -92]...      [ -23,  277,   -7, ...,   62,  494, -199]]), Y=array([[ -23,  -91,   -7, ..., -196,  -75,  -92]...      [ -23,  277,   -7, ...,   62,  494, -199]]), func=<functools.partial object>, n_jobs=40, **kwds={'w': array([ 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,... 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])})
   1084 
   1085     # TODO: in some cases, backend='threading' may be appropriate
   1086     fd = delayed(func)
   1087     ret = Parallel(n_jobs=n_jobs, verbose=0)(
   1088         fd(X, Y[s], **kwds)
-> 1089         for s in gen_even_slices(Y.shape[0], n_jobs))
        Y.shape = (581012, 100)
        n_jobs = 40
   1090 
   1091     return np.hstack(ret)
   1092 
   1093 

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=40), iterable=<generator object <genexpr>>)
    753         self.n_completed_tasks = 0
    754         try:
    755             # Only set self._iterating to True if at least a batch
    756             # was dispatched. In particular this covers the edge
    757             # case of Parallel used with an exhausted iterator.
--> 758             while self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=40)>
        iterator = <generator object <genexpr>>
    759                 self._iterating = True
    760             else:
    761                 self._iterating = False
    762 

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=40), iterator=<generator object <genexpr>>)
    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))
    604             if len(tasks) == 0:
    605                 # No more tasks available in the iterator: tell caller to stop.
    606                 return False
    607             else:
--> 608                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=40)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    609                 return True
    610 
    611     def _print(self, msg, msg_args):
    612         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=40), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    566         self.n_dispatched_tasks += len(batch)
    567         self.n_dispatched_batches += 1
    568 
    569         dispatch_timestamp = time.time()
    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
--> 571         job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    572         self._jobs.append(job)
    573 
    574     def dispatch_next(self):
    575         """Dispatch more data for parallel processing

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    105         return 1
    106 
    107     def apply_async(self, func, callback=None):
    108         """Schedule a func to be run"""
--> 109         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    110         if callback:
    111             callback(result)
    112         return result
    113 

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    321 
    322 class ImmediateResult(object):
    323     def __init__(self, batch):
    324         # Don't delay the application, to avoid keeping the input
    325         # arguments in memory
--> 326         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    327 
    328     def get(self):
    329         return self.results
    330 

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <functools.partial object>
        args = (array([[ -23,  -91,   -7, ..., -196,  -75,  -92]...      [ -23,  277,   -7, ...,   62,  494, -199]]), array([[ -23,  -91,   -7, ..., -196,  -75,  -92]...      [ -23,  -35,   -7, ...,   62,  -75, -199]]))
        kwargs = {'w': array([ 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,... 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])}
        self.items = [(<functools.partial object>, (array([[ -23,  -91,   -7, ..., -196,  -75,  -92]...      [ -23,  277,   -7, ...,   62,  494, -199]]), array([[ -23,  -91,   -7, ..., -196,  -75,  -92]...      [ -23,  -35,   -7, ...,   62,  -75, -199]])), {'w': array([ 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,... 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/pairwise.py in _pairwise_callable(X=array([[ -23.,  -91.,   -7., ..., -196.,  -75., ...[ -23.,  277.,   -7., ...,   62.,  494., -199.]]), Y=array([[ -23.,  -91.,   -7., ..., -196.,  -75., ...[ -23.,  -35.,   -7., ...,   62.,  -75., -199.]]), metric=<function weighted_jaccard>, **kwds={'w': array([ 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,... 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])})
   1113             x = X[i]
   1114             out[i, i] = metric(x, x, **kwds)
   1115 
   1116     else:
   1117         # Calculate all cells
-> 1118         out = np.empty((X.shape[0], Y.shape[0]), dtype='float')
        out = undefined
        X.shape = (581012, 100)
        Y.shape = (14526, 100)
   1119         iterator = itertools.product(range(X.shape[0]), range(Y.shape[0]))
   1120         for i, j in iterator:
   1121             out[i, j] = metric(X[i], Y[j], **kwds)
   1122 

MemoryError: 
___________________________________________________________________________
